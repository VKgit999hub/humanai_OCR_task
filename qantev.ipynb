{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have used Two datasets - Rodrigo dataset and a synthetic dataset generated using VRD generator "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rodrigo dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AHvLu96KZCpE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_image_paths(file_path):\n",
        "    \"\"\"Load image paths from a txt file.\"\"\"\n",
        "    with open(file_path, \"r\") as f:\n",
        "        return [line.strip() for line in f.readlines()]\n",
        "\n",
        "def load_transcriptions(transcription_file):\n",
        "    \"\"\"Load transcriptions from the transcription txt file and return a dictionary mapping image paths to transcriptions.\"\"\"\n",
        "    transcription_dict = {}\n",
        "    with open(transcription_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\" \", 1)  # Split into image path and transcription\n",
        "            if len(parts) == 2:\n",
        "                image_path, transcription = parts\n",
        "                transcription_dict[image_path] = transcription\n",
        "    return transcription_dict\n",
        "\n",
        "def create_dataframe(image_paths, transcription_dict):\n",
        "    \"\"\"Create a DataFrame with image paths and their transcriptions.\"\"\"\n",
        "    data = {\"image_path\": image_paths, \"transcription\": [transcription_dict.get(img, \"\") for img in image_paths]}\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# File paths\n",
        "train_txt = \"/teamspace/studios/this_studio/train.txt\"\n",
        "val_txt = \"/teamspace/studios/this_studio/validation.txt\"\n",
        "test_txt = \"/teamspace/studios/this_studio/test.txt\"\n",
        "transcription_txt = \"/teamspace/studios/this_studio/transcriptions.txt\"\n",
        "\n",
        "# Load data\n",
        "train_paths = load_image_paths(train_txt)\n",
        "val_paths = load_image_paths(val_txt)\n",
        "test_paths = load_image_paths(test_txt)\n",
        "transcriptions = load_transcriptions(transcription_txt)\n",
        "\n",
        "# Create DataFrames\n",
        "df_train = create_dataframe(train_paths, transcriptions)\n",
        "df_val = create_dataframe(val_paths, transcriptions)\n",
        "df_test = create_dataframe(test_paths, transcriptions)\n",
        "df_train = pd.concat([df_train , df_test] , ignore_index = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>transcription</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rodrigo_00006_00</td>\n",
              "      <td>Historia De España_Del</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rodrigo_00006_01</td>\n",
              "      <td>Arçobispo. Do Rodri_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rodrigo_00006_02</td>\n",
              "      <td>go. Traducida En Ro_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rodrigo_00006_03</td>\n",
              "      <td>mançe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rodrigo_00008_00</td>\n",
              "      <td>E ste es el libro de la Cronica de es</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_path                          transcription\n",
              "0  Rodrigo_00006_00                 Historia De España_Del\n",
              "1  Rodrigo_00006_01                   Arçobispo. Do Rodri_\n",
              "2  Rodrigo_00006_02                   go. Traducida En Ro_\n",
              "3  Rodrigo_00006_03                                  mançe\n",
              "4  Rodrigo_00008_00  E ste es el libro de la Cronica de es"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14010"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "VRD dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_vrd = pd.read_csv('/teamspace/studios/this_studio/GEN_IMAGES_DF.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>path</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>image_5_1.png</td>\n",
              "      <td>Nunca ofendí la fe con la esperanza;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>image_0_1.png</td>\n",
              "      <td>Valencia insigne, patria venturosa,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>image_12_1.png</td>\n",
              "      <td>Clarín, que rosicleres troglodita,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>image_11_1.png</td>\n",
              "      <td>Tiemble la tierra, y con furor horrendo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>image_3_1.png</td>\n",
              "      <td>De tu muerte que fue un breve suspiro,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0            path                                     text\n",
              "0           0   image_5_1.png     Nunca ofendí la fe con la esperanza;\n",
              "1           1   image_0_1.png      Valencia insigne, patria venturosa,\n",
              "2           2  image_12_1.png       Clarín, que rosicleres troglodita,\n",
              "3           3  image_11_1.png  Tiemble la tierra, y con furor horrendo\n",
              "4           4   image_3_1.png   De tu muerte que fue un breve suspiro,"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vrd.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_vrd = df_vrd.drop(columns = ['Unnamed: 0'])\n",
        "df_vrd = df_vrd.rename(columns={'path': 'image_path' , 'text' : 'transcription'})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>transcription</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image_5_1.png</td>\n",
              "      <td>Nunca ofendí la fe con la esperanza;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image_0_1.png</td>\n",
              "      <td>Valencia insigne, patria venturosa,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image_12_1.png</td>\n",
              "      <td>Clarín, que rosicleres troglodita,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image_11_1.png</td>\n",
              "      <td>Tiemble la tierra, y con furor horrendo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image_3_1.png</td>\n",
              "      <td>De tu muerte que fue un breve suspiro,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       image_path                            transcription\n",
              "0   image_5_1.png     Nunca ofendí la fe con la esperanza;\n",
              "1   image_0_1.png      Valencia insigne, patria venturosa,\n",
              "2  image_12_1.png       Clarín, que rosicleres troglodita,\n",
              "3  image_11_1.png  Tiemble la tierra, y con furor horrendo\n",
              "4   image_3_1.png   De tu muerte que fue un breve suspiro,"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vrd.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15368"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_vrd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_vrd_val = df_vrd.sample(frac = 0.05 , random_state = 42)\n",
        "df_vrd_train = df_vrd.drop(df_vrd_val.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_vrd_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_val_final = pd.concat([df_val ,df_vrd_val] , ignore_index = True ).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_train_final = pd.concat([df_train , df_vrd_train] , ignore_index = True).sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "final Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28610"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_train_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>transcription</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rodrigo_00491_11</td>\n",
              "      <td>doña vrraca e doña Eluira. E porque doña vrrac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rodrigo_00189_21</td>\n",
              "      <td>aqui sino A morir mala muerte. tornad vos para...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rodrigo_00182_01</td>\n",
              "      <td>astraguemos e pues no son nrōs yguales en Arma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rodrigo_00536_01</td>\n",
              "      <td>cho. E veyendo los condes qe el rei, lo vno co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image_270_1.png</td>\n",
              "      <td>Ya Flori sale el campo, todo es flores,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_path                                      transcription\n",
              "0  Rodrigo_00491_11  doña vrraca e doña Eluira. E porque doña vrrac...\n",
              "1  Rodrigo_00189_21  aqui sino A morir mala muerte. tornad vos para...\n",
              "2  Rodrigo_00182_01  astraguemos e pues no son nrōs yguales en Arma...\n",
              "3  Rodrigo_00536_01  cho. E veyendo los condes qe el rei, lo vno co...\n",
              "4   image_270_1.png            Ya Flori sale el campo, todo es flores,"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1768"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_val_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>transcription</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rodrigo_00407_06</td>\n",
              "      <td>ouo al ynfante don Ordoño y de la otra ouo a l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rodrigo_00121_16</td>\n",
              "      <td>es Verdadera creencia y verdadera Regla de chr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rodrigo_00180_13</td>\n",
              "      <td>67 ¶ Agora cuenta la historia de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rodrigo_00399_12</td>\n",
              "      <td>don Ermigio obispo de tui e martiriaronlo En c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rodrigo_00217_07</td>\n",
              "      <td>la espina de la sebe qe se mette por el pie o ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_path                                      transcription\n",
              "0  Rodrigo_00407_06  ouo al ynfante don Ordoño y de la otra ouo a l...\n",
              "1  Rodrigo_00121_16  es Verdadera creencia y verdadera Regla de chr...\n",
              "2  Rodrigo_00180_13                   67 ¶ Agora cuenta la historia de\n",
              "3  Rodrigo_00399_12  don Ermigio obispo de tui e martiriaronlo En c...\n",
              "4  Rodrigo_00217_07  la espina de la sebe qe se mette por el pie o ..."
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "correcting the nuances of 17th century spanish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "# Load spaCy's Spanish language model\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "def is_valid_spanish_word(word):\n",
        "    \"\"\"Check if a word exists in modern Spanish using spaCy.\"\"\"\n",
        "    lexeme = nlp.vocab[word]\n",
        "    return lexeme.is_oov == False  # If False, the word is in the vocabulary\n",
        "\n",
        "def modify_u_v(word):\n",
        "    \"\"\"Try replacing 'v' with 'u' or vice versa and check if the word exists in Spanish.\"\"\"\n",
        "    if is_valid_spanish_word(word):\n",
        "        return word  # If the word is already valid, return as is\n",
        "\n",
        "    # Try replacing 'v' with 'u' and check again\n",
        "    modified_word = word.replace('v', 'u').replace('V' , 'U')\n",
        "    if is_valid_spanish_word(modified_word):\n",
        "        return modified_word\n",
        "\n",
        "    # Try replacing 'u' with 'v' and check again\n",
        "    modified_word = word.replace('u', 'v').replace('U' , 'V')\n",
        "    if is_valid_spanish_word(modified_word):\n",
        "        return modified_word\n",
        "\n",
        "    return word  # If no valid modification, return original word\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Normalize 'ſ' (long s) to 's'\n",
        "    text = text.replace('ſ', 's')\n",
        "\n",
        "    # Tokenize text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Modify 'u' and 'v' based on dictionary lookup\n",
        "    processed_words = [modify_u_v(word) for word in words]\n",
        "\n",
        "    # Reconstruct text\n",
        "    text = ' '.join(processed_words)\n",
        "\n",
        "    # Remove accents except for 'ñ'\n",
        "    text = re.sub(r'(?<!ñ)[áàâä]', 'a', text)\n",
        "    text = re.sub(r'(?<!ñ)[éèêë]', 'e', text)\n",
        "    text = re.sub(r'(?<!ñ)[íìîï]', 'i', text)\n",
        "    text = re.sub(r'(?<!ñ)[óòôö]', 'o', text)\n",
        "    text = re.sub(r'(?<!ñ)[úùûü]', 'u', text)\n",
        "\n",
        "    # Replace macrons with appropriate expansion\n",
        "    text = re.sub(r'([aeiou])̄', r'\\1n', text)  # Replace vowels with macrons with 'n'\n",
        "    text = re.sub(r'q̄', 'que', text)  # Replace 'q̄' with 'que'\n",
        "\n",
        "    # Leave split words as is\n",
        "    text = text.replace('-\\n', '\\n')\n",
        "\n",
        "    # Replace 'ç' with 'z'\n",
        "    text = text.replace('ç', 'z')\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'doña urraca e doña Eluira. E porque doña urraca era sa'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess_text('doña vrraca e doña Eluira. E porque doña vrraca era sa')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_final['transcription'] = df_train_final['transcription'].apply(preprocess_text)\n",
        "df_val_final['transcription'] = df_val_final['transcription'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'doña urraca e doña Eluira. E porque doña urraca era sa'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train_final.iloc[0]['transcription']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NS6MG7oXbVho"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Prepares image by applying adaptive thresholding, noise removal, and inversion.\"\"\"\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "\n",
        "    # Adaptive Thresholding\n",
        "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 5, 5)\n",
        "    # _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    \n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Create a mask to filter out small components\n",
        "    mask = np.zeros_like(binary)\n",
        "\n",
        "    # Keep only larger contours\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 5:  # Adjust threshold based on noise size\n",
        "            cv2.drawContours(mask, [cnt], -1, 255, thickness=cv2.FILLED)\n",
        "\n",
        "    # Apply mask to original image\n",
        "    binary = cv2.bitwise_and(binary, mask)                               \n",
        "\n",
        "    # Remove small noise using connected components\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary , connectivity=8)\n",
        "    for i in range(1, num_labels):\n",
        "        area = stats[i, cv2.CC_STAT_AREA]\n",
        "        if area < 5:  # Threshold for noise removal\n",
        "            binary[labels == i] = 0\n",
        "\n",
        "    # Invert image\n",
        "    processed = cv2.bitwise_not(binary)\n",
        "\n",
        "    return processed\n",
        "\n",
        "def remove_borders(image):\n",
        "    \"\"\"Removes borders from scanned documents using edge and line detection.\"\"\"\n",
        "    if len(image.shape) == 3:  # Check if image has color channels\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "    binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "    # Detect horizontal and vertical lines\n",
        "    kernel_h = np.ones((1, 50), np.uint8)\n",
        "    kernel_v = np.ones((50, 1), np.uint8)\n",
        "\n",
        "    horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_h)\n",
        "    vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_v)\n",
        "\n",
        "    # Combine detected lines\n",
        "    lines = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0)\n",
        "\n",
        "    # Detect strong lines using Hough Transform\n",
        "    edges = cv2.Canny(lines, 50, 150, apertureSize=3)\n",
        "    lines_detected = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=200, maxLineGap=5)\n",
        "\n",
        "    mask = np.ones_like(binary) * 255  # White background\n",
        "    if lines_detected is not None:\n",
        "        for line in lines_detected:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            cv2.line(mask, (x1, y1), (x2, y2), 0, 3)  # Draw detected lines in black\n",
        "\n",
        "    # Dilate and subtract the mask from the original image\n",
        "    mask = cv2.dilate(mask, np.ones((5, 5), np.uint8), iterations=2)\n",
        "    result = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "    return result\n",
        "\n",
        "def enhance_sharpness(image):\n",
        "    \"\"\"Enhances the sharpness of the image using PIL.\"\"\"\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    enhancer = ImageEnhance.Sharpness(pil_image)\n",
        "    enhanced_image = enhancer.enhance(2)  # Increase sharpness factor\n",
        "    return cv2.cvtColor(np.array(enhanced_image), cv2.COLOR_RGB2BGR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "img_path = '/teamspace/studios/this_studio/GEN_IMAGES/image_1_2.png'\n",
        "image = cv2.imread(img_path)\n",
        "preprocessed = preprocess_image(image)\n",
        "# borderless = remove_borders(preprocessed)\n",
        "sharpened_img = enhance_sharpness(preprocessed)\n",
        "plt.imshow(sharpened_img, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(81, 540, 3)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"qkv_bias\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.49.0\"\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"cross_attention_hidden_size\": 768,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layernorm_embedding\": false,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"trocr\",\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": true,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": false,\n",
            "  \"use_learned_position_embeddings\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrOCRProcessor, AutoTokenizer, VisionEncoderDecoderModel\n",
        "processor = TrOCRProcessor.from_pretrained(\"qantev/trocr-base-spanish\" , use_fast = True)\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"qantev/trocr-base-spanish\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50265"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                                            Param #\n",
              "==========================================================================================\n",
              "VisionEncoderDecoderModel                                         --\n",
              "├─ViTModel: 1-1                                                   --\n",
              "│    └─ViTEmbeddings: 2-1                                         443,904\n",
              "│    │    └─ViTPatchEmbeddings: 3-1                               590,592\n",
              "│    │    └─Dropout: 3-2                                          --\n",
              "│    └─ViTEncoder: 2-2                                            --\n",
              "│    │    └─ModuleList: 3-3                                       85,026,816\n",
              "│    └─LayerNorm: 2-3                                             1,536\n",
              "│    └─ViTPooler: 2-4                                             --\n",
              "│    │    └─Linear: 3-4                                           590,592\n",
              "│    │    └─Tanh: 3-5                                             --\n",
              "├─TrOCRForCausalLM: 1-2                                           --\n",
              "│    └─TrOCRDecoderWrapper: 2-5                                   --\n",
              "│    │    └─TrOCRDecoder: 3-6                                     246,739,968\n",
              "│    └─Linear: 2-6                                                51,471,360\n",
              "==========================================================================================\n",
              "Total params: 384,864,768\n",
              "Trainable params: 384,864,768\n",
              "Non-trainable params: 0\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TrOCRProcessor:\n",
              "- image_processor: ViTImageProcessorFast {\n",
              "  \"crop_size\": null,\n",
              "  \"default_to_square\": true,\n",
              "  \"do_center_crop\": null,\n",
              "  \"do_convert_rgb\": null,\n",
              "  \"do_normalize\": true,\n",
              "  \"do_rescale\": true,\n",
              "  \"do_resize\": true,\n",
              "  \"image_mean\": [\n",
              "    0.5,\n",
              "    0.5,\n",
              "    0.5\n",
              "  ],\n",
              "  \"image_processor_type\": \"ViTImageProcessorFast\",\n",
              "  \"image_std\": [\n",
              "    0.5,\n",
              "    0.5,\n",
              "    0.5\n",
              "  ],\n",
              "  \"processor_class\": \"TrOCRProcessor\",\n",
              "  \"resample\": 2,\n",
              "  \"rescale_factor\": 0.00392156862745098,\n",
              "  \"size\": {\n",
              "    \"height\": 384,\n",
              "    \"width\": 384\n",
              "  }\n",
              "}\n",
              "\n",
              "- tokenizer: RobertaTokenizerFast(name_or_path='qantev/trocr-base-spanish', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
              "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
              "}\n",
              ")\n",
              "\n",
              "{\n",
              "  \"processor_class\": \"TrOCRProcessor\"\n",
              "}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Already configured acc to the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "config = LoraConfig(\n",
        "    r=16,  # Rank (adjust as needed)\n",
        "    lora_alpha=16,  # Scaling factor\n",
        "    lora_dropout=0.1,  # Dropout for LoRA layers\n",
        "    target_modules=[\n",
        "        \"query\" , \"value\" , \"q_proj\" , \"v_proj\"\n",
        "    ]\n",
        ")\n",
        "# Apply LoRA\n",
        "model = get_peft_model(model, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                                                      Param #\n",
              "====================================================================================================\n",
              "PeftModel                                                                   --\n",
              "├─LoraModel: 1-1                                                            --\n",
              "│    └─VisionEncoderDecoderModel: 2-1                                       --\n",
              "│    │    └─ViTModel: 3-1                                                   87,833,088\n",
              "│    │    └─TrOCRForCausalLM: 3-2                                           301,258,752\n",
              "====================================================================================================\n",
              "Total params: 389,091,840\n",
              "Trainable params: 4,227,072\n",
              "Non-trainable params: 384,864,768\n",
              "===================================================================================================="
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable Parameters: 4227072/389091840 (1.09%)\n"
          ]
        }
      ],
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable Parameters: {trainable_params}/{total_params} ({100 * trainable_params/total_params:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
        "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "model.decoder.config.vocab_size = processor.tokenizer.vocab_size\n",
        "model.config.vocab_size = model.decoder.config.vocab_size\n",
        "model.config.eos_token_id = processor.tokenizer.sep_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GenerationConfig\n",
        "\n",
        "# Define a generation configuration\n",
        "gen_config = GenerationConfig(\n",
        "    max_length=64,\n",
        "    early_stopping=True,\n",
        "    no_repeat_ngram_size=3,\n",
        "    length_penalty=2.0,\n",
        "    num_beams=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ujQUdwrTc_SC"
      },
      "outputs": [],
      "source": [
        "def preprocessing(img_path):\n",
        "  image = cv2.imread(img_path)\n",
        "  preprocessed = preprocess_image(image)\n",
        "  # borderless = remove_borders(preprocessed)\n",
        "  sharpened_img = enhance_sharpness(preprocessed)\n",
        "  pixel_values = processor(sharpened_img, return_tensors=\"pt\").pixel_values.squeeze()\n",
        "  return pixel_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 384, 384])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessing(img_path).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "U2W6NIT8cRqd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader , Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "class SpanishDocumentsDataset(Dataset):\n",
        "    def __init__(self, df , processor):\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image_path = self.df.iloc[idx]['image_path']\n",
        "            if image_path[0] == \"R\":\n",
        "                image_path = os.path.join( '/teamspace/studios/this_studio/images', image_path) + '.png'\n",
        "            else:\n",
        "                image_path = os.path.join( '/teamspace/studios/this_studio/GEN_IMAGES', image_path) \n",
        "            pixel_values = preprocessing(image_path)\n",
        "            text = self.df.iloc[idx]['transcription']\n",
        "            labels = self.processor.tokenizer(text, return_tensors=\"pt\").input_ids.squeeze()\n",
        "            # labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
        "            return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to load data for index {idx}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "tOJrENbpe41p"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(batch):\n",
        "    try:\n",
        "        pixel_values = [item['pixel_values'] for item in batch]\n",
        "        labels = [item['labels'] for item in batch]\n",
        "        labels = pad_sequence(labels, batch_first=True, padding_value= processor.tokenizer.pad_token_id)\n",
        "        pixel_values = torch.stack(pixel_values)\n",
        "        return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Failed to collate batch: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "69YrMcrAe5m1"
      },
      "outputs": [],
      "source": [
        "train_dataset = SpanishDocumentsDataset(df_train_final, processor)\n",
        "val_dataset = SpanishDocumentsDataset(df_val_final, processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 50262])\n"
          ]
        }
      ],
      "source": [
        "# Dummy image input\n",
        "pixel_values = torch.rand(1, 3, 384, 384)  # Batch size 1, RGB image\n",
        "\n",
        "# Generate decoder inputs (empty start token)\n",
        "decoder_input_ids = torch.tensor([[model.config.decoder_start_token_id]])\n",
        "\n",
        "# Forward pass\n",
        "outputs = model(pixel_values=pixel_values, decoder_input_ids=decoder_input_ids)\n",
        "\n",
        "# Logits\n",
        "print(outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DElWj1qZfXVe"
      },
      "outputs": [],
      "source": [
        "b_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "klFOFKaMfTaL"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=b_size, shuffle=True, collate_fn=custom_collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=b_size, shuffle=False, collate_fn=custom_collate_fn)\n",
        "# test_dataloader = DataLoader(test_dataset, batch_size=b_size, shuffle=False, collate_fn=custom_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pixel_values': tensor([[[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  0.2784, -0.8667,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  0.2784, -0.8667,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  0.2784, -0.8667,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  0.2784, -0.8667,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  0.2784, -0.8667,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  0.2784, -0.8667,  ...,  1.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 1.0000,  0.2784, -0.8667,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  0.2784, -0.8667,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 1.0000,  0.2784, -0.8667,  ...,  1.0000,  1.0000,  1.0000]]]]), 'labels': tensor([[    0,  2794,   897,   842, 23495,  2424, 18309,  2684,  7296,  2601,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,   438,  1180,  1250,   254,  5003,  1423, 38426,  1535,  6527,\n",
            "         12495, 32468,   293, 15441,  3774, 14628,   366,     6,   364,  2677,\n",
            "         29587,     2,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0, 29420, 25872, 11156,  2231,   242,     7,  5016,  1448,  9500,\n",
            "           139,    83,  2636,  2231,   242,  8541,   271,   364,   218, 16630,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  1343,  3774,  1611,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  2839,  3774,   263,  2084,   261,   263,   856, 14609,    10,\n",
            "          2471,  4699,  3774,  5951,   763,   257,  6009,  4843,   366,  1423,\n",
            "          3774, 13145,     2,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  5016,  6641,  1020,  2424,  6719,  6491,  1423, 13081, 21748,\n",
            "           241,  2953,   897,  4435, 18195,   263,  2269,   366,   364,  9007,\n",
            "          3876,  3840,     2,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  1343,   242, 16690, 10913,  7427,   181,  5347, 14555,  6821,\n",
            "         13235,  1073,  4082,     4,  1423,  9007,   271, 33098,  3840,   897,\n",
            "         17676,   102,     2,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,   417,   673, 14379,  9163, 13249,   102,   856, 12733,  2424,\n",
            "           769,   118,   218,   248,  5602,  1001,  1615,  6154,  2359,   364,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0, 10766, 36823,   493,  2084,   991,   366,  3342,   385,  2095,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,   347,  5564,   263,  3774,  9958,  1615, 13228,  7367,  2527,\n",
            "          2489, 16742,   139,     6,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0, 12150,  3407,  1615,  8196,  1177,  3391,  8462,  1020,   162,\n",
            "         15380,   906,   859,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  1794,    37,    37, 11156,  3089,  5219,     6,   385,   922,\n",
            "          1755,  1423,   524,   368,  5166,   116,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  3407,  3304,   257,  5766,  1177,  1615, 11188,  1023,  1001,\n",
            "          5540, 18829, 17838,     6,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,   329,  2413,   642, 38183,   263,     7,  1329,   139,   218,\n",
            "           741, 45738,  3567,   263, 39750,     7,   417, 21866,  1177,   897,\n",
            "         11806,     2,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0, 37419,   293, 14429,   254,   261,  1177,  1615,   740,  5255,\n",
            "           139,  1423,  3304,   260,   579,  9173,  5234, 20761,   295,   338,\n",
            "         38183,   842,  6303,   368,  2269,   366,     4,   359,     2],\n",
            "        [    0,   219,  1615, 40201,  1168,  9689,  5384,   102,    10,  3304,\n",
            "           102,  3816,  1290,   102,     4,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,   523, 26093,  2520,  2379,   218,  6778,  2694,   417,  1725,\n",
            "          2102,     6,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  3865, 34686,   102, 11021,  1243,   385,  3851,  1423, 14429,\n",
            "           254,   859,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0, 30616,   705,  1020,  1615,  4533, 26764,    10,  5573, 28312,\n",
            "           293,   263,   968,  6005,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  2794,  2628, 42085, 20870, 44182,  1020,  1177, 15549,   548,\n",
            "          6797,   102,     6,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  5408, 32325,   102,  6821,   102,     6, 37787,  3181,     6,\n",
            "         10272,  1192, 14701,  3843,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,   642,  3663,  3391,   162,  1392, 22461,   102,  2628, 19316,\n",
            "          2478,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,   510,  3663,  1192,  2953,   748,   366,   842,   571, 20870,\n",
            "             6, 12635,   718,   281,   139,     6,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,   506,  7414,   261,  3840,    13, 11978, 29588,  1001, 15149,\n",
            "           385,  7367,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  4082,  6821,   257,   853,     4,   381,  2677,  5502,   784,\n",
            "          4308,   139,  1615, 43572,  1076,  2471,  6491,   263, 21748,   493,\n",
            "          2231,   242,  2714,   740,  5084,  2478,     2,     1,     1],\n",
            "        [    0,  2871,  1423,  1136,   293,  2520,  7003,   897, 12987,  5219,\n",
            "             4,  1423,  1615,   769,   118,   579,  9173,  5234,  2714,  1990,\n",
            "          6527,  2764,     2,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  2794,   748,   282,   385,   493,  1177,  1615,    83, 14182,\n",
            "          3137,   139,    10,   856,  6971,     6,   364, 16690,   523,   385,\n",
            "           493,  3304,   260,  2764, 28041,   281,  1423,     2,     1],\n",
            "        [    0,   523,   364,   267, 33037,   271,   117,   181, 23259,    11,\n",
            "           757,   405,  2102,   131,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0, 25930,  8461,   385,   922,  1755, 14429,  8530,     6,   842,\n",
            "          1368, 23747,   910,  1020,     4,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,  2977,  2271,   748, 27042,   364, 12206,  2645,  1020,   459,\n",
            "          1192,  4600,  5847,  1906,  8954,   364,  1615,   769,   118,  2677,\n",
            "         18195,     2,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0, 37335,   897,  1177,   991, 11742, 15503,   493,  2084,  2694,\n",
            "         11409,     6,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    0,   219, 45821,  6070,  3851,    10, 12369,  1177,  1615,  1368,\n",
            "         11168,  2628, 13961,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1]])}\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "    print(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load\n",
        "import evaluate\n",
        "# from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "bleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    try:\n",
        "        # Compute Character Error Rate (CER) and Word Error Rate (WER)\n",
        "        decoded_preds , decoded_labels = eval_pred\n",
        "        cer = cer_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "        wer = wer_metric.compute(predictions=decoded_preds, references=decoded_preds)\n",
        "\n",
        "        # Compute BLEU Score\n",
        "        bleu_score = bleu.compute(predictions=decoded_preds, references=[[ref] for ref in decoded_labels], smooth_method=\"exp\")\n",
        "\n",
        "        return {\n",
        "            \"cer\": cer,\n",
        "            \"wer\": wer,\n",
        "            \"Bleu\": bleu_score['score'],\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Failed to compute metrics: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "895"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import VisionEncoderDecoderModel\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "# Training and evaluation function\n",
        "def train_model(model, train_dataloader, val_dataloader, optimizer, device,scheduler, epochs=5, grad_accum_steps=1):\n",
        "    \n",
        "    train_l = []\n",
        "    eval_l = []\n",
        "    wer = []\n",
        "    cer = []\n",
        "    bleu = []\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar = tqdm(train_dataloader, desc=\"Training\", leave=False)\n",
        "\n",
        "        for step, batch in enumerate(progress_bar):  # Use the same tqdm instance\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            input_ids = batch[\"labels\"][:, :-1].to(device).contiguous()\n",
        "            labels = batch[\"labels\"][:, 1:].to(device).contiguous()\n",
        "\n",
        "            outputs = model(pixel_values=pixel_values, decoder_input_ids=input_ids).logits\n",
        "            loss_fn = torch.nn.CrossEntropyLoss(ignore_index=processor.tokenizer.pad_token_id)\n",
        "            loss = loss_fn(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
        "            loss /= grad_accum_steps  # Normalize loss for gradient accumulation\n",
        "\n",
        "            loss.backward()\n",
        "            total_loss += loss.item() * grad_accum_steps\n",
        "            train_l.append(loss.item() * grad_accum_steps)\n",
        "\n",
        "            if (step + 1) % grad_accum_steps == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # Dynamically update loss in tqdm progress bar\n",
        "            progress_bar.set_postfix(loss=f\"{loss.item() * grad_accum_steps:.4f}\")\n",
        "        train_loss =  total_loss / len(train_dataloader)\n",
        "        \n",
        "        print(f\"Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        wer_v = 0\n",
        "        cer_v = 0\n",
        "        bleu_v = 0\n",
        "        predictions, references = [], []\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm(val_dataloader, desc=\"Evaluating\", leave=False)\n",
        "\n",
        "            for batch in progress_bar :\n",
        "                pixel_values = batch[\"pixel_values\"].to(device)\n",
        "                input_ids = batch[\"labels\"][:,:-1].to(device).contiguous()\n",
        "                labels = batch[\"labels\"][:,1:].to(device).contiguous()\n",
        "\n",
        "                outputs = model(pixel_values=pixel_values, decoder_input_ids=input_ids).logits\n",
        "                # outputs = torch.argmax(outputs , dim = -1).squeeze()\n",
        "                loss_fn = torch.nn.CrossEntropyLoss(ignore_index = processor.tokenizer.pad_token_id)\n",
        "                loss = loss_fn(outputs.view(-1,outputs.size(-1)) , labels.view(-1))\n",
        "                loss /= grad_accum_steps\n",
        "                outputs_g = model.generate(pixel_values=pixel_values, generation_config=gen_config)\n",
        "                decoded_preds = processor.tokenizer.batch_decode(outputs_g, skip_special_tokens=True)\n",
        "                decoded_labels = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "                metric = compute_metrics((decoded_preds , decoded_labels))\n",
        "\n",
        "                predictions.extend(decoded_preds)\n",
        "                references.extend(decoded_labels)\n",
        "                wer.append(metric['wer'])\n",
        "                cer.append(metric['cer'])\n",
        "                bleu.append(metric['Bleu'])\n",
        "                val_loss += loss.item() * grad_accum_steps\n",
        "                wer_v +=metric['wer']\n",
        "                cer_v += metric['cer']\n",
        "                bleu_v += metric['Bleu']\n",
        "                eval_l.append(loss.item() * grad_accum_steps)\n",
        "                progress_bar.set_postfix(val_loss=loss.item() * grad_accum_steps , wer = metric['wer'] , cer = metric['cer'] , bleu = metric['Bleu'] )\n",
        "\n",
        "            val_loss =  val_loss / len(val_dataloader)\n",
        "            wer_v /= len(val_dataloader)\n",
        "            cer_v /= len(val_dataloader)\n",
        "            bleu_v /= len(val_dataloader)\n",
        "        \n",
        "        \n",
        "\n",
        "        print(f\"val Loss: {val_loss:.4f} , wer : {wer_v:.4f} , cer : {cer_v:.4f} , bleu_score : {bleu_v:.4f} \")\n",
        "\n",
        "        # Print sample predictions\n",
        "        # Ensure there are at least three samples\n",
        "        num_samples = min(3, len(decoded_preds))\n",
        "\n",
        "        # Select three random indices\n",
        "        random_indices = random.sample(range(len(decoded_preds)), num_samples)\n",
        "\n",
        "        # Print the selected samples\n",
        "        for i in random_indices:\n",
        "            print(f\"Pred: {decoded_preds[i]}\")\n",
        "            print(f\"Ref: {decoded_labels[i]}\\n\")\n",
        "\n",
        "        # Save model checkpoint\n",
        "        save_path = f\"/teamspace/studios/this_studio/2nd_qantev_model\"\n",
        "        os.makedirs(save_path, exist_ok=True)  # Ensure directory exists\n",
        "\n",
        "        # Save only model weights\n",
        "        torch.save(model.state_dict(), os.path.join(save_path, f\"model_checkpoint_epoch_{epoch+1}.pth\"))\n",
        "\n",
        "    return train_l , eval_l , wer , cer , bleu \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model, optimizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_new = model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, \n",
        "    T_0=1,  # Number of epochs before the first restart\n",
        "    T_mult=2,  # Multiplicative factor for the restart period\n",
        "    eta_min=1e-6  # Minimum learning rate\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 1.2957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.7138 , wer : 0.0000 , cer : 0.0996 , bleu_score : 54.1187 \n",
            "Pred: Taz, las brabras y aunque alimentura,\n",
            "Ref: Trago las brasas, y aunque alla sintieron\n",
            "\n",
            "Pred: y el planeta, que nunca para, dora\n",
            "Ref: y el planeta, que nunca para, dora\n",
            "\n",
            "Pred: ¡Al miño de amor fiestas celebra,\n",
            "Ref: Al milagro de amor fiestas celebra,\n",
            "\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.7375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.5700 , wer : 0.0000 , cer : 0.0736 , bleu_score : 63.3751 \n",
            "Pred: Al mismo de amor, fiestas celebra,\n",
            "Ref: Al milagro de amor fiestas celebra,\n",
            "\n",
            "Pred: y el planeta, que nunca para, dora\n",
            "Ref: y el planeta, que nunca para, dora\n",
            "\n",
            "Pred: y de las ondas se escapo el piloto,\n",
            "Ref: y de las ondas se escapo el piloto,\n",
            "\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.6020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.5141 , wer : 0.0000 , cer : 0.0662 , bleu_score : 66.5271 \n",
            "Pred: y el planeta, que nunca para, dora\n",
            "Ref: y el planeta, que nunca para, dora\n",
            "\n",
            "Pred: Al mirio de amor, fiestas celebra,\n",
            "Ref: Al milagro de amor fiestas celebra,\n",
            "\n",
            "Pred: Juez fue home muy paciente e sabidor y entendi\n",
            "Ref: Juez fue home muy paciente e sabidor y entendi\n",
            "\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.5014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.4562 , wer : 0.0000 , cer : 0.0579 , bleu_score : 70.0939 \n",
            "Pred: y de las ondas se escapo el piloto,\n",
            "Ref: y de las ondas se escapo el piloto,\n",
            "\n",
            "Pred: pues tambien veene a ser aplraso tego,\n",
            "Ref: pues tambien viene a ser aplauso tuyo.\n",
            "\n",
            "Pred: Al mirio de amor, fiestas celebra,\n",
            "Ref: Al milagro de amor fiestas celebra,\n",
            "\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.4588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.4737 , wer : 0.0000 , cer : 0.0610 , bleu_score : 68.9387 \n",
            "Pred: y si es de noche, luego nace el dia\n",
            "Ref: y si es de noche, luego nace el dia;\n",
            "\n",
            "Pred: de dos soles que en gloria juzgo iguales\n",
            "Ref: de dos soles que en gloria juzgo iguales,\n",
            "\n",
            "Pred: Juez fue home muy paciente e sabidor y entendi\n",
            "Ref: Juez fue home muy paciente e sabidor y entendi\n",
            "\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.4616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.4349 , wer : 0.0000 , cer : 0.0574 , bleu_score : 71.1043 \n",
            "Pred: y si es de noche, luego nace el dia,\n",
            "Ref: y si es de noche, luego nace el dia;\n",
            "\n",
            "Pred: Taga, las bienes y amor, alli sintiene,\n",
            "Ref: Trago las brasas, y aunque alla sintieron\n",
            "\n",
            "Pred: pues tambien viene a ser aplraso tego,\n",
            "Ref: pues tambien viene a ser aplauso tuyo.\n",
            "\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.3969\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.4026 , wer : 0.0000 , cer : 0.0515 , bleu_score : 73.3556 \n",
            "Pred: y el planeta, que nunca para, dora\n",
            "Ref: y el planeta, que nunca para, dora\n",
            "\n",
            "Pred: y de las ondas se escapo el piloto,\n",
            "Ref: y de las ondas se escapo el piloto,\n",
            "\n",
            "Pred: de dos soles que en gloria fuzgo iguales\n",
            "Ref: de dos soles que en gloria juzgo iguales,\n",
            "\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.3389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3842 , wer : 0.0000 , cer : 0.0487 , bleu_score : 74.1700 \n",
            "Pred: y el planeta, que nunca para, dora\n",
            "Ref: y el planeta, que nunca para, dora\n",
            "\n",
            "Pred: Al mirio de amor, fiestas celebra,\n",
            "Ref: Al milagro de amor fiestas celebra,\n",
            "\n",
            "Pred: y si es de noche, luego nace el dia,\n",
            "Ref: y si es de noche, luego nace el dia;\n",
            "\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.3085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3782 , wer : 0.0000 , cer : 0.0478 , bleu_score : 74.8427 \n",
            "Pred: pues tambien veene a ser aplraso tego,\n",
            "Ref: pues tambien viene a ser aplauso tuyo.\n",
            "\n",
            "Pred: de dos soles que en gloria fuzgo iguales\n",
            "Ref: de dos soles que en gloria juzgo iguales,\n",
            "\n",
            "Pred: y de las ondas se escapo el piloto,\n",
            "Ref: y de las ondas se escapo el piloto,\n",
            "\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.3674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.4210 , wer : 0.0000 , cer : 0.0544 , bleu_score : 71.8305 \n",
            "Pred: y le las ondas se escapo el piloto,\n",
            "Ref: y de las ondas se escapo el piloto,\n",
            "\n",
            "Pred: de dos soles que en gloria juzgo iguales\n",
            "Ref: de dos soles que en gloria juzgo iguales,\n",
            "\n",
            "Pred: Al mirio de amor, fiestas celebra,\n",
            "Ref: Al milagro de amor fiestas celebra,\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Assuming train_dataloader and val_dataloader are already created\n",
        "train_l , eval_l , wer , cer , bleu = train_model(model, train_dataloader, val_dataloader, optimizer, device,scheduler, epochs=10, grad_accum_steps=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
